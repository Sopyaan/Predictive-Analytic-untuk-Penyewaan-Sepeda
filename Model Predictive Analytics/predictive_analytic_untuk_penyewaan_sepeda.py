# -*- coding: utf-8 -*-
"""Predictive Analytic untuk Penyewaan Sepeda

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DoFrOn0Nst2hxE37vEXbRg64yLdYOfTh

# Problem Statement

Sistem penyewaan sepeda telah menjadi alternatif transportasi yang semakin populer di kota-kota besar. Namun, permintaan terhadap sepeda sangat fluktuatif dan dipengaruhi oleh berbagai faktor seperti cuaca, musim, serta hari kerja atau hari libur. Ketidakpastian ini menyulitkan operator dalam mengelola ketersediaan sepeda dan merencanakan strategi distribusi yang efisien. Dengan adanya data historis dan informasi lingkungan yang terus dikumpulkan, muncul peluang untuk membangun sistem prediktif yang dapat membantu pengambilan keputusan secara lebih akurat dan berbasis data.

Berdasarkan konteks tersebut, proyek ini berfokus pada dua pertanyaan utama:

- Bagaimana cara membangun model yang dapat memprediksi jumlah penyewaan sepeda secara akurat berdasarkan faktor-faktor seperti cuaca, musim, dan hari kerja?
- Apa saja faktor utama yang paling memengaruhi jumlah penyewaan sepeda, dan bagaimana cara mengoptimalkan model prediktif untuk menangkap hubungan tersebut secara tepat?

# Data Load
"""

# Commented out IPython magic to ensure Python compatibility.
# Import library yang dibutuhkan
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
# %matplotlib inline
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score

# load dataset
url = 'https://raw.githubusercontent.com/Sopyaan/Predictive-Analytic-untuk-Penyewaan-Sepeda/refs/heads/main/Dataset/hour.csv'
bike_hour = pd.read_csv(url)
bike_hour

"""# Exploratory Data Analyisis

## Melihat bentuk data
"""

bike_hour.info()

"""Dtype 'Date' dari 'Object' harus di ubah kedalam 'Datetime'"""

bike_hour['dteday'] = pd.to_datetime(bike_hour['dteday'])

bike_hour.describe()

"""## Melihat missing value"""

bike_hour.isnull().sum()

"""## Melihat duplikasi"""

bike_hour.duplicated().sum()

"""## Melihat outliers"""

numerical_cols = ['temp', 'atemp', 'hum', 'windspeed', 'casual', 'registered', 'cnt']

# Buat boxplot untuk tiap kolom numerik
plt.figure(figsize=(15, 10))
for i, col in enumerate(numerical_cols, 1):
    plt.subplot(3, 3, i)
    sns.boxplot(data=bike_hour, y=col)
    plt.title(f'Boxplot of {col}')
plt.tight_layout()
plt.show()

# Fungsi untuk mendeteksi outlier menggunakan metode IQR
def detect_outliers_iqr(data, column):
    Q1 = data[column].quantile(0.25)
    Q3 = data[column].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    outliers = data[(data[column] < lower_bound) | (data[column] > upper_bound)]
    return outliers


# Cek outlier untuk semua kolom numerik
for col in numerical_cols:
    outliers = detect_outliers_iqr(bike_hour, col)
    print(f"{col}: {len(outliers)} outliers")

"""Berdasarkan analisis statistik dan visualisasi boxplot, beberapa fitur seperti windspeed, casual, registered, dan cnt menunjukkan adanya outlier.
Namun, setelah ditinjau, nilai-nilai ini merepresentasikan variasi alami dalam perilaku pengguna sepeda (misalnya lonjakan saat weekend, cuaca bagus, atau musim tertentu). Oleh karena itu, outlier tidak dihapus, karena masih relevan dan berpotensi memberi informasi penting dalam proses pemodelan.

## Data vizualisasi

### Boxplot
"""

plt.figure(figsize=(10,6))
sns.histplot(data=bike_hour, x='cnt', bins=40, kde=True)

"""### Heatmap"""

plt.figure(figsize=(12,8))
corr_matrix = bike_hour.corr()
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=".2f")

"""# Data preparation

Berdasarkan hasil eksplorasi data, diketahui bahwa dataset tidak mengandung nilai yang hilang (missing values) maupun data duplikat. Oleh karena itu, tahap data preparation tidak memerlukan proses imputasi maupun penghapusan data duplikat.

## Pemisahan Fitur dan Target
"""

# Fitur dan target
X = bike_hour[['season', 'yr', 'mnth', 'hr', 'holiday', 'weekday',
             'workingday', 'weathersit', 'temp', 'atemp', 'hum', 'windspeed']]
y = bike_hour['cnt']

"""## Split data jadi train-test"""

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""# Modeling"""

# Siapkan dataframe untuk analisis model
models = pd.DataFrame(index=['train_mse', 'test_mse'],
                      columns=['RandomForest', 'Boosting', 'Linear Regression', 'KNN'])

"""## Random forest"""

from sklearn.ensemble import RandomForestRegressor

RF = RandomForestRegressor(n_estimators=50, max_depth=16, random_state=55, n_jobs=-1)
RF.fit(X_train, y_train)

models.loc['train_mse','RandomForest'] = mean_squared_error(y_pred=RF.predict(X_train), y_true=y_train)

"""## Gradient Boosting"""

from sklearn.ensemble import GradientBoostingRegressor

Boosting = GradientBoostingRegressor(n_estimators=100, learning_rate=0.3, max_depth=3, random_state=55)
Boosting.fit(X_train, y_train)

models.loc['train_mse','Boosting'] = mean_squared_error(y_pred=Boosting.predict(X_train), y_true=y_train)

"""## Linear Regression"""

from sklearn.linear_model import LinearRegression

lin_reg = LinearRegression()
lin_reg.fit(X_train, y_train)

"""## KNN"""

from sklearn.neighbors import KNeighborsRegressor

knn = KNeighborsRegressor(n_neighbors=10)
knn.fit(X_train, y_train)

models.loc['train_mse','knn'] = mean_squared_error(y_pred = knn.predict(X_train), y_true=y_train)

"""# Evaluasi Model"""

# Buat variabel mse yang isinya adalah dataframe nilai mse data train dan test pada masing-masing algoritma
mse = pd.DataFrame(columns=['train', 'test'], index=['RF','lin_reg','Boosting', 'KNN'])

# Buat dictionary untuk setiap algoritma yang digunakan
model_dict = {'RF': RF, 'Boosting': Boosting, 'lin_reg': lin_reg, 'KNN': knn}

# Hitung Mean Squared Error masing-masing algoritma pada data train dan test
for name, model in model_dict.items():
    mse.loc[name, 'train'] = mean_squared_error(y_true=y_train, y_pred=model.predict(X_train))/1e3
    mse.loc[name, 'test'] = mean_squared_error(y_true=y_test, y_pred=model.predict(X_test))/1e3

# Panggil mse
mse

fig, ax = plt.subplots()
mse.sort_values(by='test', ascending=False).plot(kind='barh', ax=ax, zorder=3)
ax.grid(zorder=0)

prediksi = X_test.iloc[:1].copy()
pred_dict = {'y_true':y_test[:1]}
for name, model in model_dict.items():
    pred_dict['prediksi_'+name] = model.predict(prediksi).round(1)

pd.DataFrame(pred_dict)

"""# Kesimpulan

Penjelasan:
- Random Forest memiliki performa terbaik dengan error terkecil pada train (0.39) maupun test (1.83), menunjukkan model ini sangat baik dalam menangkap pola dari data tanpa overfitting yang parah.
- Boosting dan KNN juga menunjukkan performa cukup baik, namun masih kalah dari Random Forest dalam hal akurasi prediksi.
- Linear Regression memiliki error tertinggi, yang menunjukkan bahwa hubungan antar fitur mungkin tidak linear atau model terlalu sederhana untuk data ini.

Berdasarkan hasil evaluasi, Random Forest menjadi model paling andal dengan prediksi mendekati nilai aktual dan error terkecil di antara semua model yang diuji. Oleh karena itu, Random Forest dipilih sebagai model terbaik untuk implementasi akhir dalam proses prediksi.
"""

# Ambil model terbaik untuk visualisasi
best_model = RandomForestRegressor(n_estimators=100, random_state=42)
best_model.fit(X_train, y_train)
y_pred_best = best_model.predict(X_test)

plt.figure(figsize=(10,6))
plt.scatter(y_test, y_pred_best, alpha=0.3, color='teal')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
plt.xlabel('Actual cnt')
plt.ylabel('Predicted cnt')
plt.title('Random Forest - Actual vs Predicted')
plt.grid(True)
plt.tight_layout()
plt.show()